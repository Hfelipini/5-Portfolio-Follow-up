{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install yfinance --upgrade --no-cache-dir --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "InfosToCopy = pd.read_csv('orders.csv', delimiter=\";\", header=0)\n",
    "assetsList = sorted(InfosToCopy['Ativo'].unique())\n",
    "\n",
    "for position in range(len(assetsList)):\n",
    "    data = yf.download(assetsList[position]+\".SA\", start=\"2022-09-26\", progress=False)\n",
    "    local = \"output1/\"+assetsList[position]+\".csv\"\n",
    "    data.to_csv(local,index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-09-26', '2022-09-27', '2022-09-28', '2022-09-29', '2022-09-30', '2022-10-03', '2022-10-04', '2022-10-05', '2022-10-06', '2022-10-07', '2022-10-10', '2022-10-11', '2022-10-13', '2022-10-14', '2022-10-17', '2022-10-18', '2022-10-19', '2022-10-20', '2022-10-21', '2022-10-24', '2022-10-25', '2022-10-26', '2022-10-27', '2022-10-28', '2022-10-31', '2022-11-01', '2022-11-03', '2022-11-04', '2022-11-07', '2022-11-08', '2022-11-09', '2022-11-10', '2022-11-11', '2022-11-14', '2022-11-16', '2022-11-17', '2022-11-18', '2022-11-21', '2022-11-22', '2022-11-23', '2022-11-24', '2022-11-25', '2022-11-28', '2022-11-29', '2022-11-30', '2022-12-01', '2022-12-02', '2022-12-05', '2022-12-06', '2022-12-07', '2022-12-08', '2022-12-09', '2022-12-12', '2022-12-13', '2022-12-14', '2022-12-15', '2022-12-16', '2022-12-19', '2022-12-20', '2022-12-21', '2022-12-22', '2022-12-23', '2022-12-26', '2022-12-27', '2022-12-28', '2022-12-29', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06', '2023-01-09', '2023-01-10', '2023-01-11', '2023-01-12']\n"
     ]
    }
   ],
   "source": [
    "dateCsv = pd.read_csv('output1/BRFS3.csv')\n",
    "dateList = sorted(dateCsv['Date'].unique())\n",
    "print(dateList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AALR3</th>\n",
       "      <th>AGRO3</th>\n",
       "      <th>BBDC4</th>\n",
       "      <th>BOAS3</th>\n",
       "      <th>BRFS3</th>\n",
       "      <th>BRKM5</th>\n",
       "      <th>CURY3</th>\n",
       "      <th>DIRR3</th>\n",
       "      <th>EZTC3</th>\n",
       "      <th>...</th>\n",
       "      <th>RECV3</th>\n",
       "      <th>ROMI3</th>\n",
       "      <th>SBFG3</th>\n",
       "      <th>SOJA3</th>\n",
       "      <th>SUZB3</th>\n",
       "      <th>TPIS3</th>\n",
       "      <th>TSLA34</th>\n",
       "      <th>TTEN3</th>\n",
       "      <th>UNIP6</th>\n",
       "      <th>WEGE3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>21.200001</td>\n",
       "      <td>27.660000</td>\n",
       "      <td>14.04</td>\n",
       "      <td>7.21</td>\n",
       "      <td>7.71</td>\n",
       "      <td>22.410000</td>\n",
       "      <td>11.64</td>\n",
       "      <td>14.45</td>\n",
       "      <td>13.15</td>\n",
       "      <td>...</td>\n",
       "      <td>31.120001</td>\n",
       "      <td>14.19</td>\n",
       "      <td>11.59</td>\n",
       "      <td>9.96</td>\n",
       "      <td>49.950001</td>\n",
       "      <td>0.90</td>\n",
       "      <td>19.110001</td>\n",
       "      <td>8.62</td>\n",
       "      <td>82.589996</td>\n",
       "      <td>37.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>21.360001</td>\n",
       "      <td>27.610001</td>\n",
       "      <td>14.65</td>\n",
       "      <td>7.30</td>\n",
       "      <td>8.38</td>\n",
       "      <td>23.090000</td>\n",
       "      <td>11.85</td>\n",
       "      <td>14.71</td>\n",
       "      <td>13.14</td>\n",
       "      <td>...</td>\n",
       "      <td>31.080000</td>\n",
       "      <td>14.78</td>\n",
       "      <td>11.32</td>\n",
       "      <td>10.04</td>\n",
       "      <td>50.259998</td>\n",
       "      <td>0.96</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>8.62</td>\n",
       "      <td>81.720001</td>\n",
       "      <td>37.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>21.290001</td>\n",
       "      <td>27.820000</td>\n",
       "      <td>15.06</td>\n",
       "      <td>7.30</td>\n",
       "      <td>8.64</td>\n",
       "      <td>23.230000</td>\n",
       "      <td>12.10</td>\n",
       "      <td>15.02</td>\n",
       "      <td>13.52</td>\n",
       "      <td>...</td>\n",
       "      <td>31.629999</td>\n",
       "      <td>14.75</td>\n",
       "      <td>12.05</td>\n",
       "      <td>10.70</td>\n",
       "      <td>49.939999</td>\n",
       "      <td>0.95</td>\n",
       "      <td>18.299999</td>\n",
       "      <td>8.70</td>\n",
       "      <td>80.010002</td>\n",
       "      <td>38.029999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>21.170000</td>\n",
       "      <td>27.809999</td>\n",
       "      <td>14.66</td>\n",
       "      <td>7.43</td>\n",
       "      <td>8.69</td>\n",
       "      <td>23.389999</td>\n",
       "      <td>11.95</td>\n",
       "      <td>14.65</td>\n",
       "      <td>13.32</td>\n",
       "      <td>...</td>\n",
       "      <td>32.029999</td>\n",
       "      <td>14.65</td>\n",
       "      <td>11.70</td>\n",
       "      <td>10.54</td>\n",
       "      <td>50.610001</td>\n",
       "      <td>0.96</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>8.62</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>37.919998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>21.290001</td>\n",
       "      <td>27.889999</td>\n",
       "      <td>15.10</td>\n",
       "      <td>7.59</td>\n",
       "      <td>9.06</td>\n",
       "      <td>23.049999</td>\n",
       "      <td>12.12</td>\n",
       "      <td>15.14</td>\n",
       "      <td>13.68</td>\n",
       "      <td>...</td>\n",
       "      <td>32.200001</td>\n",
       "      <td>15.80</td>\n",
       "      <td>12.21</td>\n",
       "      <td>10.68</td>\n",
       "      <td>49.980000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>19.240000</td>\n",
       "      <td>8.86</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>37.549999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date      AALR3      AGRO3  BBDC4  BOAS3  BRFS3      BRKM5  CURY3  \\\n",
       "68  2023-01-04  21.200001  27.660000  14.04   7.21   7.71  22.410000  11.64   \n",
       "69  2023-01-05  21.360001  27.610001  14.65   7.30   8.38  23.090000  11.85   \n",
       "70  2023-01-06  21.290001  27.820000  15.06   7.30   8.64  23.230000  12.10   \n",
       "71  2023-01-09  21.170000  27.809999  14.66   7.43   8.69  23.389999  11.95   \n",
       "72  2023-01-10  21.290001  27.889999  15.10   7.59   9.06  23.049999  12.12   \n",
       "\n",
       "    DIRR3  EZTC3  ...      RECV3  ROMI3  SBFG3  SOJA3      SUZB3  TPIS3  \\\n",
       "68  14.45  13.15  ...  31.120001  14.19  11.59   9.96  49.950001   0.90   \n",
       "69  14.71  13.14  ...  31.080000  14.78  11.32  10.04  50.259998   0.96   \n",
       "70  15.02  13.52  ...  31.629999  14.75  12.05  10.70  49.939999   0.95   \n",
       "71  14.65  13.32  ...  32.029999  14.65  11.70  10.54  50.610001   0.96   \n",
       "72  15.14  13.68  ...  32.200001  15.80  12.21  10.68  49.980000   1.01   \n",
       "\n",
       "       TSLA34  TTEN3      UNIP6      WEGE3  \n",
       "68  19.110001   8.62  82.589996  37.400002  \n",
       "69  18.400000   8.62  81.720001  37.480000  \n",
       "70  18.299999   8.70  80.010002  38.029999  \n",
       "71  19.680000   8.62  80.000000  37.919998  \n",
       "72  19.240000   8.86  80.000000  37.549999  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(dateList, columns=['Date'])\n",
    "\n",
    "path = \"output1\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "for files in csv_files:\n",
    "    Ticker = files.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    df1 = pd.read_csv('output1/'+Ticker+'.csv')\n",
    "    df2 = df1[['Date', 'Close']].copy().rename(columns={'Close': Ticker})\n",
    "    df=pd.merge(df,df2, on='Date', how='inner')\n",
    "\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AALR3\n",
      "AGRO3\n",
      "AURA33\n",
      "BABA34\n",
      "BBDC4\n",
      "BOAS3\n",
      "BRFS3\n",
      "BRKM5\n",
      "BRML3\n",
      "CSNA3\n",
      "CURY3\n",
      "DIRR3\n",
      "EZTC3\n",
      "GGBR3\n",
      "GOAU4\n",
      "IFCM3\n",
      "INTB3\n",
      "JBSS3\n",
      "JHSF3\n",
      "KEPL3\n",
      "KLBN4\n",
      "LVTC3\n",
      "MDIA3\n",
      "MILS3\n",
      "MLAS3\n",
      "MOVI3\n",
      "MRFG3\n",
      "MYPK3\n",
      "OIBR3\n",
      "PORT3\n",
      "RANI3\n",
      "RECV3\n",
      "ROMI3\n",
      "SBFG3\n",
      "SOJA3\n",
      "SUZB3\n",
      "TPIS3\n",
      "TSLA34\n",
      "TTEN3\n",
      "UNIP6\n",
      "WEGE3\n"
     ]
    }
   ],
   "source": [
    "path = \"output1\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "FlagOnOff = 0\n",
    "\n",
    "for files in csv_files:\n",
    "    df = pd.read_csv(files, header='infer', index_col=0)\n",
    "    df['Ticker'] = files.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    print(files.split(\"\\\\\")[-1].split(\".\")[0])\n",
    "    if FlagOnOff == 0:\n",
    "        df.to_csv('output2/append.csv', mode='w', header=True)\n",
    "        FlagOnOff = 1\n",
    "    else:\n",
    "        df.to_csv('output2/append.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InfosToCopy2 = pd.read_csv('listaComRSI.csv', delimiter=\";\", header=None)\n",
    "FlagOnOff = 0\n",
    "for position in range(len(InfosToCopy2)):\n",
    "    local = \"output1/\"+InfosToCopy2.iloc[position][0]+\".csv\"\n",
    "    df5 = pd.read_csv(local, index_col=0)\n",
    "    df5['Ticker'] = InfosToCopy2.iloc[position][0]\n",
    "    if FlagOnOff == 0:\n",
    "        df5.to_csv('output3/filter5.csv', mode='a', header=True)\n",
    "        FlagOnOff = 1\n",
    "    else:\n",
    "        df5.to_csv('output3/filter5.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InfosToCopy = pd.read_csv('lista2.csv', delimiter=\";\", header=None)\n",
    "for position in range(len(InfosToCopy)):\n",
    "    data = yf.download(InfosToCopy.iloc[position][0]+\".SA\", period=\"max\")\n",
    "    local = \"output1/\"+InfosToCopy.iloc[position][0]+\".csv\"\n",
    "    data.to_csv(local,index=True,header=True)\n",
    "    print(position, len(InfosToCopy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_RSI(data, column='Close', window=9, path=\"XXXX\"):    \n",
    "\n",
    "    # Establish gains and losses for each day\n",
    "    data['Variation'] = data[column].diff()\n",
    "    data = data[1:]\n",
    "    data['Gain'] = np.where(data['Variation'] > 0, data['Variation'], 0)\n",
    "    data['Loss'] = np.where(data['Variation'] < 0, data['Variation'], 0)\n",
    "\n",
    "    # Calculate simple averages so we can initialize the classic averages\n",
    "    simple_avg_gain = data['Gain'].rolling(window).mean()\n",
    "    simple_avg_loss = data['Loss'].abs().rolling(window).mean()\n",
    "\n",
    "    classic_avg_gain = simple_avg_gain.copy()\n",
    "    classic_avg_loss = simple_avg_loss.copy()\n",
    "\n",
    "    for i in range(window, len(classic_avg_gain)):\n",
    "        classic_avg_gain[i] = (classic_avg_gain[i - 1] * (window - 1) + data['Gain'].iloc[i]) / window\n",
    "        classic_avg_loss[i] = (classic_avg_loss[i - 1] * (window - 1) + data['Loss'].abs().iloc[i]) / window\n",
    "    \n",
    "    # Calculate the RSI\n",
    "    data['Simple RS'] = simple_avg_gain / simple_avg_loss\n",
    "    data['Classic RS'] = classic_avg_gain / classic_avg_loss\n",
    "\n",
    "    data['Simple RSIf'] = 100 - (100 / (1 + data['Simple RS']))\n",
    "    data['Classic RSIf'] = 100 - (100 / (1 + data['Classic RS']))\n",
    "\n",
    "    data['Ticker'] = path.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "    low_min = data['Low'].rolling(14).min()\n",
    "    high_max = data['High'].rolling(14).max()\n",
    "    \n",
    "    # Fast Stochastic\n",
    "    data['k_fast'] = 100 * (data['Close'] - low_min)/(high_max - low_min)\n",
    "\n",
    "    # Slow Stochastic\n",
    "    data['d_slow'] = data['k_fast'].rolling(3).mean()\n",
    "\n",
    "    # Export to CSV\n",
    "    local = \"output2/\"+path.split(\"\\\\\")[-1]\n",
    "    data.to_csv(local, index=True, sep=\",\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"output1\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "for files in csv_files:\n",
    "    df = pd.read_csv(files, header='infer', index_col=0)\n",
    "    build_RSI(data=df, column=\"Close\", window=9, path=files.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output2\\BRFS3.csv\")\n",
    "#rslt_df = df[(df['Classic RSIf'] <= 15)] #164\n",
    "#rslt_df = df[(df['Classic RSIf'] <= 15) & (df['k_slow'] <= 15)] #142\n",
    "rslt_df = df[(df['Classic RSIf'] <= 15) & (df['d_slow'] <= 15)] #145\n",
    "df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output2\\ITUB4.csv\")\n",
    "rslt_df = df[(df['Classic RSIf'] <= 15)] #187\n",
    "#rslt_df = df[(df['Classic RSIf'] <= 15) & (df['d_slow'] <= 15)] #145\n",
    "rslt_df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"output2\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "for files in csv_files:\n",
    "    df = pd.read_csv(files, header='infer', index_col=0)\n",
    "    rslt_df = df[(df['Classic RSIf'] <= 15) & (df['d_slow'] <= 15)]\n",
    "    rslt_df.to_csv('output3/filter1c.csv', mode='a', header=True)\n",
    "    rslt_df = df[(df['Classic RSIf'] >= 85) & (df['d_slow'] >= 85)]\n",
    "    rslt_df.to_csv('output3/filter1v.csv', mode='a', header=True)\n",
    "    #print(files)\n",
    "    #build_RSI(data=df, column=\"Close\", window=9, path=files.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output3/filter1c.csv\")\n",
    "df = df[(df['Date'] != \"Date\")]\n",
    "df['Open'] = pd.to_numeric(df['Open'])\n",
    "df['High'] = pd.to_numeric(df['High'])\n",
    "df['Low'] = pd.to_numeric(df['Low'])\n",
    "df['Close'] = pd.to_numeric(df['Close'])\n",
    "df['Adj Close'] = pd.to_numeric(df['Adj Close'])\n",
    "df['Volume'] = pd.to_numeric(df['Volume'])\n",
    "df['Variation'] = pd.to_numeric(df['Variation'])\n",
    "df['Gain'] = pd.to_numeric(df['Gain'])\n",
    "df['Loss'] = pd.to_numeric(df['Loss'])\n",
    "df['Simple RS'] = pd.to_numeric(df['Simple RS'])\n",
    "df['Classic RS'] = pd.to_numeric(df['Classic RS'])\n",
    "df['Simple RSIf'] = pd.to_numeric(df['Simple RSIf'])\n",
    "df['Classic RSIf'] = pd.to_numeric(df['Classic RSIf'])\n",
    "df['k_fast'] = pd.to_numeric(df['k_fast'])\n",
    "df['d_slow'] = pd.to_numeric(df['d_slow'])\n",
    "df['Category'] = \"C\"\n",
    "df = df[(df['Volume'] >= 1000000)]\n",
    "df.to_csv('output3/filter2c.csv', header=True)\n",
    "\n",
    "# Volume >= 1.000.000 - 1716 linhas\n",
    "# Qualquer Volume - 58 mil linhas\n",
    "# Volume >= 10.000 - 6006 linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output3/filter1v.csv\")\n",
    "df = df[(df['Date'] != \"Date\")]\n",
    "df['Open'] = pd.to_numeric(df['Open'])\n",
    "df['High'] = pd.to_numeric(df['High'])\n",
    "df['Low'] = pd.to_numeric(df['Low'])\n",
    "df['Close'] = pd.to_numeric(df['Close'])\n",
    "df['Adj Close'] = pd.to_numeric(df['Adj Close'])\n",
    "df['Volume'] = pd.to_numeric(df['Volume'])\n",
    "df['Variation'] = pd.to_numeric(df['Variation'])\n",
    "df['Gain'] = pd.to_numeric(df['Gain'])\n",
    "df['Loss'] = pd.to_numeric(df['Loss'])\n",
    "df['Simple RS'] = pd.to_numeric(df['Simple RS'])\n",
    "df['Classic RS'] = pd.to_numeric(df['Classic RS'])\n",
    "df['Simple RSIf'] = pd.to_numeric(df['Simple RSIf'])\n",
    "df['Classic RSIf'] = pd.to_numeric(df['Classic RSIf'])\n",
    "df['k_fast'] = pd.to_numeric(df['k_fast'])\n",
    "df['d_slow'] = pd.to_numeric(df['d_slow'])\n",
    "df['Category'] = \"V\"\n",
    "df = df[(df['Volume'] >= 1000000)]\n",
    "df.to_csv('output3/filter2v.csv', header=True)\n",
    "\n",
    "# Volume >= 1.000.000 - 1716 linhas\n",
    "# Qualquer Volume - 58 mil linhas\n",
    "# Volume >= 10.000 - 6006 linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output3/filter2v.csv\", index_col=0)\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv = pd.read_csv(\"output3/filter2v.csv\", index_col=0)\n",
    "dfc = pd.read_csv(\"output3/filter2c.csv\", index_col=0)\n",
    "\n",
    "dfc.to_csv('output3/filter3.csv', mode='a', header=True)\n",
    "dfv.to_csv('output3/filter3.csv', mode='a', header=False)\n",
    "\n",
    "df3 = pd.read_csv(\"output3/filter3.csv\", index_col=0)\n",
    "df3.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Ticker', 'Date', 'Category', 'Adj Close']\n",
    "df3.to_csv('output3/filter4.csv', header=True, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(\"output3/filter4.csv\", index_col=0)\n",
    "df4.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InfosToCopy2 = pd.read_csv('listaComRSI.csv', delimiter=\";\", header=None)\n",
    "FlagOnOff = 0\n",
    "for position in range(len(InfosToCopy2)):\n",
    "    local = \"output1/\"+InfosToCopy2.iloc[position][0]+\".csv\"\n",
    "    df5 = pd.read_csv(local, index_col=0)\n",
    "    df5['Ticker'] = InfosToCopy2.iloc[position][0]\n",
    "    if FlagOnOff == 0:\n",
    "        df5.to_csv('output3/filter5.csv', mode='a', header=True)\n",
    "        FlagOnOff = 1\n",
    "    else:\n",
    "        df5.to_csv('output3/filter5.csv', mode='a', header=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
