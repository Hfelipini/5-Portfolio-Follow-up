{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install yfinance --upgrade --no-cache-dir --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "InfosToCopy = pd.read_csv('orders.csv', delimiter=\";\", header=0)\n",
    "assetsList = sorted(InfosToCopy['Ativo'].unique())\n",
    "\n",
    "for position in range(len(assetsList)):\n",
    "    data = yf.download(assetsList[position]+\".SA\", start=\"2022-09-26\")\n",
    "    #data = yf.download(\"TSLA34.SA\", start=\"2022-09-26\")\n",
    "    local = \"output1/\"+assetsList[position]+\".csv\"\n",
    "    data.to_csv(local,index=True,header=True)\n",
    "    #print(position, len(assetsList))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(\"TSLA34.SA\", start=\"2022-09-26\")\n",
    "local = \"output1/TSLA34.csv\"\n",
    "data.to_csv(local,index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateCsv = pd.read_csv('output1/BRFS3.csv')\n",
    "dateList = sorted(dateCsv['Date'].unique())\n",
    "print(dateList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(dateList, columns=['Date'])\n",
    "df1 = pd.read_csv('output1/BRFS3.csv')\n",
    "df2 = df1[['Date', 'Close']].copy().rename(columns={'Close': 'BRFS3'})\n",
    "inner_join=pd.merge(df,df2, on='Date', how='inner')\n",
    "inner_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AALR3\n",
      "AGRO3\n",
      "BBDC4\n",
      "BOAS3\n",
      "BRFS3\n",
      "BRKM5\n",
      "BRML3\n",
      "CURY3\n",
      "DIRR3\n",
      "EZTC3\n",
      "GGBR3\n",
      "GOAU4\n",
      "IFCM3\n",
      "INTB3\n",
      "JBSS3\n",
      "JHSF3\n",
      "KEPL3\n",
      "KLBN4\n",
      "LVTC3\n",
      "MDIA3\n",
      "MILS3\n",
      "MLAS3\n",
      "MOVI3\n",
      "MRFG3\n",
      "MYPK3\n",
      "OIBR3\n",
      "PORT3\n",
      "RANI3\n",
      "RECV3\n",
      "ROMI3\n",
      "SBFG3\n",
      "SOJA3\n",
      "SUZB3\n",
      "TPIS3\n",
      "TSLA34\n",
      "TTEN3\n",
      "UNIP6\n",
      "WEGE3\n"
     ]
    }
   ],
   "source": [
    "path = \"output1\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "FlagOnOff = 0\n",
    "\n",
    "for files in csv_files:\n",
    "    df = pd.read_csv(files, header='infer', index_col=0)\n",
    "    df['Ticker'] = files.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    print(files.split(\"\\\\\")[-1].split(\".\")[0])\n",
    "    if FlagOnOff == 0:\n",
    "        df.to_csv('output2/append.csv', mode='w', header=True)\n",
    "        FlagOnOff = 1\n",
    "    else:\n",
    "        df.to_csv('output2/append.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InfosToCopy2 = pd.read_csv('listaComRSI.csv', delimiter=\";\", header=None)\n",
    "FlagOnOff = 0\n",
    "for position in range(len(InfosToCopy2)):\n",
    "    local = \"output1/\"+InfosToCopy2.iloc[position][0]+\".csv\"\n",
    "    df5 = pd.read_csv(local, index_col=0)\n",
    "    df5['Ticker'] = InfosToCopy2.iloc[position][0]\n",
    "    if FlagOnOff == 0:\n",
    "        df5.to_csv('output3/filter5.csv', mode='a', header=True)\n",
    "        FlagOnOff = 1\n",
    "    else:\n",
    "        df5.to_csv('output3/filter5.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InfosToCopy = pd.read_csv('lista2.csv', delimiter=\";\", header=None)\n",
    "for position in range(len(InfosToCopy)):\n",
    "    data = yf.download(InfosToCopy.iloc[position][0]+\".SA\", period=\"max\")\n",
    "    local = \"output1/\"+InfosToCopy.iloc[position][0]+\".csv\"\n",
    "    data.to_csv(local,index=True,header=True)\n",
    "    print(position, len(InfosToCopy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_RSI(data, column='Close', window=9, path=\"XXXX\"):    \n",
    "\n",
    "    # Establish gains and losses for each day\n",
    "    data['Variation'] = data[column].diff()\n",
    "    data = data[1:]\n",
    "    data['Gain'] = np.where(data['Variation'] > 0, data['Variation'], 0)\n",
    "    data['Loss'] = np.where(data['Variation'] < 0, data['Variation'], 0)\n",
    "\n",
    "    # Calculate simple averages so we can initialize the classic averages\n",
    "    simple_avg_gain = data['Gain'].rolling(window).mean()\n",
    "    simple_avg_loss = data['Loss'].abs().rolling(window).mean()\n",
    "\n",
    "    classic_avg_gain = simple_avg_gain.copy()\n",
    "    classic_avg_loss = simple_avg_loss.copy()\n",
    "\n",
    "    for i in range(window, len(classic_avg_gain)):\n",
    "        classic_avg_gain[i] = (classic_avg_gain[i - 1] * (window - 1) + data['Gain'].iloc[i]) / window\n",
    "        classic_avg_loss[i] = (classic_avg_loss[i - 1] * (window - 1) + data['Loss'].abs().iloc[i]) / window\n",
    "    \n",
    "    # Calculate the RSI\n",
    "    data['Simple RS'] = simple_avg_gain / simple_avg_loss\n",
    "    data['Classic RS'] = classic_avg_gain / classic_avg_loss\n",
    "\n",
    "    data['Simple RSIf'] = 100 - (100 / (1 + data['Simple RS']))\n",
    "    data['Classic RSIf'] = 100 - (100 / (1 + data['Classic RS']))\n",
    "\n",
    "    data['Ticker'] = path.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "    low_min = data['Low'].rolling(14).min()\n",
    "    high_max = data['High'].rolling(14).max()\n",
    "    \n",
    "    # Fast Stochastic\n",
    "    data['k_fast'] = 100 * (data['Close'] - low_min)/(high_max - low_min)\n",
    "\n",
    "    # Slow Stochastic\n",
    "    data['d_slow'] = data['k_fast'].rolling(3).mean()\n",
    "\n",
    "    # Export to CSV\n",
    "    local = \"output2/\"+path.split(\"\\\\\")[-1]\n",
    "    data.to_csv(local, index=True, sep=\",\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"output1\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "for files in csv_files:\n",
    "    df = pd.read_csv(files, header='infer', index_col=0)\n",
    "    build_RSI(data=df, column=\"Close\", window=9, path=files.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output2\\BRFS3.csv\")\n",
    "#rslt_df = df[(df['Classic RSIf'] <= 15)] #164\n",
    "#rslt_df = df[(df['Classic RSIf'] <= 15) & (df['k_slow'] <= 15)] #142\n",
    "rslt_df = df[(df['Classic RSIf'] <= 15) & (df['d_slow'] <= 15)] #145\n",
    "df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output2\\ITUB4.csv\")\n",
    "rslt_df = df[(df['Classic RSIf'] <= 15)] #187\n",
    "#rslt_df = df[(df['Classic RSIf'] <= 15) & (df['d_slow'] <= 15)] #145\n",
    "rslt_df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"output2\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "for files in csv_files:\n",
    "    df = pd.read_csv(files, header='infer', index_col=0)\n",
    "    rslt_df = df[(df['Classic RSIf'] <= 15) & (df['d_slow'] <= 15)]\n",
    "    rslt_df.to_csv('output3/filter1c.csv', mode='a', header=True)\n",
    "    rslt_df = df[(df['Classic RSIf'] >= 85) & (df['d_slow'] >= 85)]\n",
    "    rslt_df.to_csv('output3/filter1v.csv', mode='a', header=True)\n",
    "    #print(files)\n",
    "    #build_RSI(data=df, column=\"Close\", window=9, path=files.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output3/filter1c.csv\")\n",
    "df = df[(df['Date'] != \"Date\")]\n",
    "df['Open'] = pd.to_numeric(df['Open'])\n",
    "df['High'] = pd.to_numeric(df['High'])\n",
    "df['Low'] = pd.to_numeric(df['Low'])\n",
    "df['Close'] = pd.to_numeric(df['Close'])\n",
    "df['Adj Close'] = pd.to_numeric(df['Adj Close'])\n",
    "df['Volume'] = pd.to_numeric(df['Volume'])\n",
    "df['Variation'] = pd.to_numeric(df['Variation'])\n",
    "df['Gain'] = pd.to_numeric(df['Gain'])\n",
    "df['Loss'] = pd.to_numeric(df['Loss'])\n",
    "df['Simple RS'] = pd.to_numeric(df['Simple RS'])\n",
    "df['Classic RS'] = pd.to_numeric(df['Classic RS'])\n",
    "df['Simple RSIf'] = pd.to_numeric(df['Simple RSIf'])\n",
    "df['Classic RSIf'] = pd.to_numeric(df['Classic RSIf'])\n",
    "df['k_fast'] = pd.to_numeric(df['k_fast'])\n",
    "df['d_slow'] = pd.to_numeric(df['d_slow'])\n",
    "df['Category'] = \"C\"\n",
    "df = df[(df['Volume'] >= 1000000)]\n",
    "df.to_csv('output3/filter2c.csv', header=True)\n",
    "\n",
    "# Volume >= 1.000.000 - 1716 linhas\n",
    "# Qualquer Volume - 58 mil linhas\n",
    "# Volume >= 10.000 - 6006 linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output3/filter1v.csv\")\n",
    "df = df[(df['Date'] != \"Date\")]\n",
    "df['Open'] = pd.to_numeric(df['Open'])\n",
    "df['High'] = pd.to_numeric(df['High'])\n",
    "df['Low'] = pd.to_numeric(df['Low'])\n",
    "df['Close'] = pd.to_numeric(df['Close'])\n",
    "df['Adj Close'] = pd.to_numeric(df['Adj Close'])\n",
    "df['Volume'] = pd.to_numeric(df['Volume'])\n",
    "df['Variation'] = pd.to_numeric(df['Variation'])\n",
    "df['Gain'] = pd.to_numeric(df['Gain'])\n",
    "df['Loss'] = pd.to_numeric(df['Loss'])\n",
    "df['Simple RS'] = pd.to_numeric(df['Simple RS'])\n",
    "df['Classic RS'] = pd.to_numeric(df['Classic RS'])\n",
    "df['Simple RSIf'] = pd.to_numeric(df['Simple RSIf'])\n",
    "df['Classic RSIf'] = pd.to_numeric(df['Classic RSIf'])\n",
    "df['k_fast'] = pd.to_numeric(df['k_fast'])\n",
    "df['d_slow'] = pd.to_numeric(df['d_slow'])\n",
    "df['Category'] = \"V\"\n",
    "df = df[(df['Volume'] >= 1000000)]\n",
    "df.to_csv('output3/filter2v.csv', header=True)\n",
    "\n",
    "# Volume >= 1.000.000 - 1716 linhas\n",
    "# Qualquer Volume - 58 mil linhas\n",
    "# Volume >= 10.000 - 6006 linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output3/filter2v.csv\", index_col=0)\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv = pd.read_csv(\"output3/filter2v.csv\", index_col=0)\n",
    "dfc = pd.read_csv(\"output3/filter2c.csv\", index_col=0)\n",
    "\n",
    "dfc.to_csv('output3/filter3.csv', mode='a', header=True)\n",
    "dfv.to_csv('output3/filter3.csv', mode='a', header=False)\n",
    "\n",
    "df3 = pd.read_csv(\"output3/filter3.csv\", index_col=0)\n",
    "df3.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Ticker', 'Date', 'Category', 'Adj Close']\n",
    "df3.to_csv('output3/filter4.csv', header=True, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(\"output3/filter4.csv\", index_col=0)\n",
    "df4.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InfosToCopy2 = pd.read_csv('listaComRSI.csv', delimiter=\";\", header=None)\n",
    "FlagOnOff = 0\n",
    "for position in range(len(InfosToCopy2)):\n",
    "    local = \"output1/\"+InfosToCopy2.iloc[position][0]+\".csv\"\n",
    "    df5 = pd.read_csv(local, index_col=0)\n",
    "    df5['Ticker'] = InfosToCopy2.iloc[position][0]\n",
    "    if FlagOnOff == 0:\n",
    "        df5.to_csv('output3/filter5.csv', mode='a', header=True)\n",
    "        FlagOnOff = 1\n",
    "    else:\n",
    "        df5.to_csv('output3/filter5.csv', mode='a', header=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
